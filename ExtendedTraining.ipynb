{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CaliFornia housing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGRESSION MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full,X_test,y_train_full,y_test=train_test_split(housing['data'],housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train_full,y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([\n",
    "     keras.layers.Dense(30,activation='relu',input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "sgd=optimizers.SGD(learning_rate=0.015)\n",
    "model.compile(loss='mean_squared_error',optimizers=sgd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 1.6534 - val_loss: 0.5667\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5619 - val_loss: 0.4548\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4435 - val_loss: 0.4390\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3952 - val_loss: 0.4402\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 17us/sample - loss: 0.3864 - val_loss: 0.4078\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3662 - val_loss: 0.4224\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3600 - val_loss: 0.3897\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3556 - val_loss: 0.3891\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 19us/sample - loss: 0.3507 - val_loss: 0.3845\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 18us/sample - loss: 0.3488 - val_loss: 0.3835\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,validation_data=(X_valid,y_valid),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/1 - 0s - loss: 0.3307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46972967529481696"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.0181804],\n",
       "       [1.4991875],\n",
       "       [2.3961825]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0:3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00001, 1.067  , 2.314  ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(14,8))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-sequential NN Wide and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=keras.layers.Input(shape=X_train.shape[1:]) #or shape=[featuresnumbers]\n",
    "hidden1=keras.layers.Dense(30,activation='relu')(input_)\n",
    "hidden2=keras.layers.Dense(30,activation='relu')(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_,hidden2])\n",
    "output=keras.layers.Dense(1)(concat)\n",
    "model=keras.Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 1.2759 - val_loss: 0.7136\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.6751 - val_loss: 0.6532\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5979 - val_loss: 0.6114\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5693 - val_loss: 0.5989\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5448 - val_loss: 0.5701\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5273 - val_loss: 0.5637\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.5112 - val_loss: 0.5413\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4976 - val_loss: 0.5328\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4858 - val_loss: 0.5190\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4759 - val_loss: 0.5074\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4661 - val_loss: 0.4967\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4577 - val_loss: 0.4898\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4506 - val_loss: 0.4842\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4432 - val_loss: 0.4721\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4381 - val_loss: 0.4679\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4323 - val_loss: 0.4651\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4272 - val_loss: 0.4609\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4228 - val_loss: 0.4555\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4184 - val_loss: 0.4525\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4155 - val_loss: 0.4469\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/1 - 0s - loss: 0.3322\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what if u want to use subset of fefeatures  for wide and a subset of features for deep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a=keras.layers.Input(shape=[4],name='wide')\n",
    "input_b=keras.layers.Input(shape=[6],name='deep')\n",
    "hidden1=keras.layers.Dense(30,activation='relu')(input_b)\n",
    "hidden2=keras.layers.Dense(20,activation='relu')(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_a,hidden2]) \n",
    "output=keras.layers.Dense(1)(concat)\n",
    "model=keras.Model(inputs=[input_a,input_b],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep (InputLayer)               [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           210         deep[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "wide (InputLayer)               [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 20)           620         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 24)           0           wide[0][0]                       \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            25          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer=optimizers.SGD(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A,X_train_B =X_train[:,:4],X_train[:,2:]\n",
    "X_valid_A,X_valid_B =X_valid[:,:4],X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:, :4],X_test[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 0.7606 - val_loss: 0.5238\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4824 - val_loss: 0.4949\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4366 - val_loss: 0.4632\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4131 - val_loss: 0.4345\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4007 - val_loss: 0.4299\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3911 - val_loss: 0.4192\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3827 - val_loss: 0.4098\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3791 - val_loss: 0.4045\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3703 - val_loss: 0.4038\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3641 - val_loss: 0.4050\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, \n",
    "                    epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/1 - 0s - loss: 0.2640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39147980439570523"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_test_A,X_test_B),y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Auxilary Output (Multipletasks outputs) Regression+classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a=keras.layers.Input(shape=[4],name='wide')\n",
    "input_b=keras.layers.Input(shape=[6],name='deep')\n",
    "hidden1=keras.layers.Dense(30,activation='relu')(input_b)\n",
    "hidden2=keras.layers.Dense(20,activation='relu')(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_a,hidden2]) \n",
    "output=keras.layers.Dense(1,name='main_output')(concat)\n",
    "aux_out=keras.layers.Dense(1,name='Auxulary_output')(hidden2)\n",
    "model=keras.Model(inputs=[input_a,input_b],outputs=[output,aux_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse','mse'],loss_weights=[0.9,0.1],optimizer='sgd')\n",
    "#we should pass list of losses\n",
    "#weight for main output > auxilary output since auxilary is used for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.9930 - main_output_loss: 0.8745 - Auxulary_output_loss: 2.0574 - val_loss: 0.6444 - val_main_output_loss: 0.5736 - val_Auxulary_output_loss: 1.2825\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.6099 - main_output_loss: 0.5552 - Auxulary_output_loss: 1.1015 - val_loss: 0.5759 - val_main_output_loss: 0.5238 - val_Auxulary_output_loss: 1.0446\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.5088 - main_output_loss: 0.4646 - Auxulary_output_loss: 0.9090 - val_loss: 0.5108 - val_main_output_loss: 0.4731 - val_Auxulary_output_loss: 0.8506\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4646 - main_output_loss: 0.4293 - Auxulary_output_loss: 0.7814 - val_loss: 0.4879 - val_main_output_loss: 0.4582 - val_Auxulary_output_loss: 0.7556\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.4420 - main_output_loss: 0.4132 - Auxulary_output_loss: 0.7007 - val_loss: 0.4665 - val_main_output_loss: 0.4407 - val_Auxulary_output_loss: 0.6989\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4283 - main_output_loss: 0.4039 - Auxulary_output_loss: 0.6476 - val_loss: 0.4507 - val_main_output_loss: 0.4283 - val_Auxulary_output_loss: 0.6527\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.4175 - main_output_loss: 0.3957 - Auxulary_output_loss: 0.6129 - val_loss: 0.4391 - val_main_output_loss: 0.4185 - val_Auxulary_output_loss: 0.6246\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4127 - main_output_loss: 0.3930 - Auxulary_output_loss: 0.5906 - val_loss: 0.4360 - val_main_output_loss: 0.4172 - val_Auxulary_output_loss: 0.6054\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4028 - main_output_loss: 0.3840 - Auxulary_output_loss: 0.5713 - val_loss: 0.4273 - val_main_output_loss: 0.4096 - val_Auxulary_output_loss: 0.5866\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3962 - main_output_loss: 0.3784 - Auxulary_output_loss: 0.5550 - val_loss: 0.4283 - val_main_output_loss: 0.4118 - val_Auxulary_output_loss: 0.5770\n"
     ]
    }
   ],
   "source": [
    "#2 y_trains\n",
    "history = model.fit((X_train_A, X_train_B), (y_train,y_train), \n",
    "                    epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/1 - 0s - loss: 0.2875 - main_output_loss: 0.3975 - Auxulary_output_loss: 0.5769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4166077457195105, 0.39746565, 0.57693315]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "[X_test_A, X_test_B], [y_test, y_test],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting through main output and auxilary output\n",
    "main,aux=model.predict([X_test_A[:3],X_test_B[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4896727],\n",
       "       [1.8644842],\n",
       "       [2.6530297]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.797661 ],\n",
       "       [2.2372751],\n",
       "       [2.943886 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving Model\n",
    "model.save(\"Vipra_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model\n",
    "model_l=keras.models.load_model('Vipra_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks, Rolling and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])  \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 1.8840\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.6668\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.6005\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5637\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.5342\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.5141\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4953\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4806\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4687\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3870/1 - 0s - loss: 0.5418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4870754593102507"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\") \n",
    "model.evaluate(X_valid,y_valid,verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 87us/sample - loss: 0.4515 - val_loss: 0.4810\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4447 - val_loss: 0.4746\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4399 - val_loss: 0.4701\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4344 - val_loss: 0.4676\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4295 - val_loss: 0.4617\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4270 - val_loss: 0.4639\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4228 - val_loss: 0.4555\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4191 - val_loss: 0.4536\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4158 - val_loss: 0.4501\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4134 - val_loss: 0.4478\n"
     ]
    }
   ],
   "source": [
    "#In this case, it will only save your model when its performance on\n",
    "#the validation set is the best so far. while using validationset\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model.save(\"my_keras_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")# rollback to best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/1 - 0s - loss: 0.3320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4399130249208258"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EARLY STOPPING with patience combining both checkpoints and eatly stoppage\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=15,\n",
    "restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4101 - val_loss: 0.4450\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4075 - val_loss: 0.4422\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4052 - val_loss: 0.4397\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4026 - val_loss: 0.4381\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4001 - val_loss: 0.4352\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3983 - val_loss: 0.4363\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3961 - val_loss: 0.4312\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3939 - val_loss: 0.4296\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3920 - val_loss: 0.4277\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3904 - val_loss: 0.4263\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3882 - val_loss: 0.4247\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3862 - val_loss: 0.4226\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3850 - val_loss: 0.4221\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3833 - val_loss: 0.4191\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3823 - val_loss: 0.4185\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3800 - val_loss: 0.4174\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3783 - val_loss: 0.4163\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3770 - val_loss: 0.4144\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3754 - val_loss: 0.4139\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3743 - val_loss: 0.4119\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3727 - val_loss: 0.4105\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3714 - val_loss: 0.4094\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3701 - val_loss: 0.4078\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3683 - val_loss: 0.4074\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3676 - val_loss: 0.4062\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3664 - val_loss: 0.4051\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3652 - val_loss: 0.4039\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3638 - val_loss: 0.4028\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3628 - val_loss: 0.4017\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3617 - val_loss: 0.4008\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3606 - val_loss: 0.3996\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3594 - val_loss: 0.3989\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3581 - val_loss: 0.3989\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3576 - val_loss: 0.3969\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3563 - val_loss: 0.3961\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3555 - val_loss: 0.3951\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3544 - val_loss: 0.3941\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3534 - val_loss: 0.3934\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3522 - val_loss: 0.3934\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3516 - val_loss: 0.3920\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3507 - val_loss: 0.3913\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3496 - val_loss: 0.3909\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3485 - val_loss: 0.3903\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3478 - val_loss: 0.3891\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3466 - val_loss: 0.3891\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3458 - val_loss: 0.3879\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3449 - val_loss: 0.3874\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3439 - val_loss: 0.3869\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3433 - val_loss: 0.3860\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3426 - val_loss: 0.3848\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3416 - val_loss: 0.3843\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3408 - val_loss: 0.3839\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3400 - val_loss: 0.3831\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3393 - val_loss: 0.3825\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.3382 - val_loss: 0.3834\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3376 - val_loss: 0.3817\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3370 - val_loss: 0.3806\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3362 - val_loss: 0.3805\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3354 - val_loss: 0.3799\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3348 - val_loss: 0.3801\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3340 - val_loss: 0.3789\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3336 - val_loss: 0.3787\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3329 - val_loss: 0.3780\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3322 - val_loss: 0.3774\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3314 - val_loss: 0.3770\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3309 - val_loss: 0.3766\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3302 - val_loss: 0.3759\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3297 - val_loss: 0.3760\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3288 - val_loss: 0.3758\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3282 - val_loss: 0.3746\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3277 - val_loss: 0.3741\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3271 - val_loss: 0.3733\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3268 - val_loss: 0.3731\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3258 - val_loss: 0.3733\n",
      "Epoch 75/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3255 - val_loss: 0.3716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3255 - val_loss: 0.3725\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3248 - val_loss: 0.3708\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3250 - val_loss: 0.3711\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3233 - val_loss: 0.3700\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3228 - val_loss: 0.3698\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3224 - val_loss: 0.3692\n",
      "Epoch 82/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3215 - val_loss: 0.3682\n",
      "Epoch 83/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3215 - val_loss: 0.3685\n",
      "Epoch 84/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3218 - val_loss: 0.3676\n",
      "Epoch 85/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3220 - val_loss: 0.3671\n",
      "Epoch 86/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3200 - val_loss: 0.3665\n",
      "Epoch 87/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3190 - val_loss: 0.3670\n",
      "Epoch 88/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3190 - val_loss: 0.3667\n",
      "Epoch 89/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3186 - val_loss: 0.3663\n",
      "Epoch 90/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3182 - val_loss: 0.3653\n",
      "Epoch 91/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3174 - val_loss: 0.3651\n",
      "Epoch 92/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3173 - val_loss: 0.3643\n",
      "Epoch 93/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3168 - val_loss: 0.3634\n",
      "Epoch 94/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3164 - val_loss: 0.3636\n",
      "Epoch 95/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3157 - val_loss: 0.3632\n",
      "Epoch 96/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3151 - val_loss: 0.3632\n",
      "Epoch 97/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3155 - val_loss: 0.3624\n",
      "Epoch 98/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3150 - val_loss: 0.3625\n",
      "Epoch 99/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3150 - val_loss: 0.3618\n",
      "Epoch 100/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3145 - val_loss: 0.3607\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "validation_data=(X_valid, y_valid),\n",
    "callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3870/1 - 0s - loss: 0.3327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3607498497463936"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid,y_valid,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing using TENSOR BOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir=get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "   32/11610 [..............................] - ETA: 7s - loss: 0.3005WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.155212). Check your callbacks.\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3140 - val_loss: 0.3611\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3150 - val_loss: 0.3603\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3147 - val_loss: 0.3617\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3132 - val_loss: 0.3598\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3134 - val_loss: 0.3595\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3110 - val_loss: 0.3591\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3107 - val_loss: 0.3590\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3102 - val_loss: 0.3586\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3101 - val_loss: 0.3585\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3098 - val_loss: 0.3588\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3092 - val_loss: 0.3578\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3089 - val_loss: 0.3577\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 80us/sample - loss: 0.3086 - val_loss: 0.3571\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3080 - val_loss: 0.3565\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3085 - val_loss: 0.3573\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 1s 76us/sample - loss: 0.3075 - val_loss: 0.3566\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 81us/sample - loss: 0.3072 - val_loss: 0.3556\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 92us/sample - loss: 0.3070 - val_loss: 0.3563\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.3071 - val_loss: 0.3548\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3091 - val_loss: 0.3549\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3060 - val_loss: 0.3552\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3056 - val_loss: 0.3542\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3048 - val_loss: 0.3538\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3044 - val_loss: 0.3539\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3045 - val_loss: 0.3543\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3041 - val_loss: 0.3530\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3044 - val_loss: 0.3537\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3035 - val_loss: 0.3529\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3033 - val_loss: 0.3520\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 1s 115us/sample - loss: 0.3028 - val_loss: 0.3522\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb=keras.callbacks.TensorBoard(run_logdir)\n",
    "history=model.fit(X_train,y_train,epochs=30,validation_data=(X_valid,y_valid),callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27540), started 0:02:59 ago. (Use '!kill 27540' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ee7ab13419bfdf36\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ee7ab13419bfdf36\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 357,
   "position": {
    "height": "379px",
    "left": "637px",
    "right": "20px",
    "top": "228px",
    "width": "307px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
